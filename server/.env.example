# Server Configuration
HOST=0.0.0.0
PORT=8000

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-coder:33b

# Optional: Alternative LLM provider (for future use)
# LLM_PROVIDER=ollama  # Options: ollama, anthropic, openai
# ANTHROPIC_API_KEY=your_key_here
# OPENAI_API_KEY=your_key_here

# Logging
LOG_LEVEL=INFO
